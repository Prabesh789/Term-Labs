{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "741c52fe-de8a-48ca-bb96-e88b1cadd61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import pos_tag, ne_chunk\n",
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f4c4c5f-ad0c-4060-a387-17ed7a00843c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example text for all tasks\n",
    "text = \"\"\"Natural Language Processing is an exciting field of Artificial Intelligence.\n",
    "It enables machines to understand human language. John works at Google in New York.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c7a46c1-67ff-4ef0-8160-69d8c50b986e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Tokenization: ['Natural Language Processing is an exciting field of Artificial Intelligence.', 'It enables machines to understand human language.', 'John works at Google in New York.']\n",
      "\n",
      "Word Tokenization:['Natural', 'Language', 'Processing', 'is', 'an', 'exciting', 'field', 'of', 'Artificial', 'Intelligence', '.', 'It', 'enables', 'machines', 'to', 'understand', 'human', 'language', '.', 'John', 'works', 'at', 'Google', 'in', 'New', 'York', '.']\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "def tokenize_text(text):\n",
    "    sentences = sent_tokenize(text)  # Sentence tokenization\n",
    "    words = word_tokenize(text)  # Word tokenization\n",
    "    return sentences, words\n",
    "\n",
    "sentences, words = tokenize_text(text)\n",
    "print(f\"Sentence Tokenization: {sentences}\")\n",
    "print(f\"\\nWord Tokenization:{words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dc9ba7c-3b19-49e3-866b-440377b1268d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without Stop Words:['Natural', 'Language', 'Processing', 'exciting', 'field', 'Artificial', 'Intelligence', '.', 'enables', 'machines', 'understand', 'human', 'language', '.', 'John', 'works', 'Google', 'New', 'York', '.']\n"
     ]
    }
   ],
   "source": [
    "# Stop Words Removal\n",
    "def remove_stopwords(words):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return filtered_words\n",
    "\n",
    "filtered_words = remove_stopwords(words)\n",
    "print(f\"Without Stop Words:{filtered_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e60f3c37-b6fb-4fd5-9a2b-dfaae85ebf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatized Words:['Natural', 'Language', 'Processing', 'exciting', 'field', 'Artificial', 'Intelligence', '.', 'enables', 'machine', 'understand', 'human', 'language', '.', 'John', 'work', 'Google', 'New', 'York', '.']\n"
     ]
    }
   ],
   "source": [
    "# Lemmatization\n",
    "def apply_lemmatization(words):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "lemmatized_words = apply_lemmatization(filtered_words)\n",
    "print(f\"Lemmatized Words:{lemmatized_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb04a660-ea1b-47c9-86fc-9914047c3dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tags: [('Natural', 'JJ'), ('Language', 'NNP'), ('Processing', 'NNP'), ('is', 'VBZ'), ('an', 'DT'), ('exciting', 'JJ'), ('field', 'NN'), ('of', 'IN'), ('Artificial', 'JJ'), ('Intelligence', 'NNP'), ('.', '.'), ('It', 'PRP'), ('enables', 'VBZ'), ('machines', 'NNS'), ('to', 'TO'), ('understand', 'VB'), ('human', 'JJ'), ('language', 'NN'), ('.', '.'), ('John', 'NNP'), ('works', 'VBZ'), ('at', 'IN'), ('Google', 'NNP'), ('in', 'IN'), ('New', 'NNP'), ('York', 'NNP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# Parts of Speech (POS) Tagging\n",
    "def pos_tagging(words):\n",
    "    return pos_tag(words)\n",
    "\n",
    "pos_tags = pos_tagging(words)\n",
    "print(f\"POS Tags: {pos_tags}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a52bc47-296f-4c13-880e-f3719f4a0dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named Entities:(S\n",
      "  Natural/JJ\n",
      "  Language/NNP\n",
      "  Processing/NNP\n",
      "  is/VBZ\n",
      "  an/DT\n",
      "  exciting/JJ\n",
      "  field/NN\n",
      "  of/IN\n",
      "  (ORGANIZATION Artificial/JJ Intelligence/NNP)\n",
      "  ./.\n",
      "  It/PRP\n",
      "  enables/VBZ\n",
      "  machines/NNS\n",
      "  to/TO\n",
      "  understand/VB\n",
      "  human/JJ\n",
      "  language/NN\n",
      "  ./.\n",
      "  (PERSON John/NNP)\n",
      "  works/VBZ\n",
      "  at/IN\n",
      "  (ORGANIZATION Google/NNP)\n",
      "  in/IN\n",
      "  (GPE New/NNP York/NNP)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "# Named Entity Recognition (NER)\n",
    "def named_entity_recognition(words):\n",
    "    return ne_chunk(pos_tagging(words))\n",
    "\n",
    "print(f\"Named Entities:{named_entity_recognition(words)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb486470-7c3e-4911-8526-aaf2759efbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Most Common Words: [('.', 3), ('Natural', 1), ('Language', 1), ('Processing', 1), ('exciting', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Frequency Distribution\n",
    "def frequency_distribution(words):\n",
    "    freq_dist = FreqDist(words)\n",
    "    return freq_dist.most_common(5)  # Top 5 most common words\n",
    "\n",
    "print(f\"Top 5 Most Common Words: {frequency_distribution(filtered_words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04325318-edba-49da-82d1-daaac47c7513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synonyms for 'happy': {'glad', 'well-chosen', 'happy', 'felicitous'}\n",
      "Antonyms for 'happy': {'unhappy'}\n"
     ]
    }
   ],
   "source": [
    "# Synonyms and Antonyms\n",
    "def synonyms_antonyms(word):\n",
    "    synonyms = []\n",
    "    antonyms = []\n",
    "\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonyms.append(lemma.name())\n",
    "            if lemma.antonyms():\n",
    "                antonyms.append(lemma.antonyms()[0].name())\n",
    "\n",
    "    return set(synonyms), set(antonyms)\n",
    "\n",
    "word_to_check = \"happy\"\n",
    "syns, ants = synonyms_antonyms(word_to_check)\n",
    "print(f\"Synonyms for '{word_to_check}':\", syns)\n",
    "print(f\"Antonyms for '{word_to_check}':\", ants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2f0237-1892-4606-a957-c27b1cd1df9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
