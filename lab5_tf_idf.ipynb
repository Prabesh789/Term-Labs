{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        and       are      data    fields       for     great        is  \\\n",
      "0  0.000000  0.000000  0.293048  0.000000  0.385323  0.385323  0.385323   \n",
      "1  0.313316  0.411973  0.313316  0.411973  0.000000  0.000000  0.000000   \n",
      "2  0.329928  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "   language  learning   machine  mathematics        on   popular  programming  \\\n",
      "0  0.385323  0.000000  0.000000     0.000000  0.000000  0.000000     0.293048   \n",
      "1  0.000000  0.313316  0.313316     0.000000  0.000000  0.411973     0.000000   \n",
      "2  0.000000  0.329928  0.329928     0.433816  0.433816  0.000000     0.329928   \n",
      "\n",
      "     python    relies   science  \n",
      "0  0.385323  0.000000  0.293048  \n",
      "1  0.000000  0.000000  0.313316  \n",
      "2  0.000000  0.433816  0.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Exercise 1: Compute TF-IDF Scores\n",
    "\n",
    "# Sample dataset\n",
    "documents = [\n",
    "    \"Python is a great programming language for data science.\",\n",
    "    \"Data science and machine learning are popular fields.\",\n",
    "    \"Machine learning relies on mathematics and programming.\"\n",
    "]\n",
    "\n",
    "# Step 1: Initialize the TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer() # Converts text into numerical values based on TF-IDF.\n",
    "\n",
    "# Step 2: Fit and transform the documents\n",
    "tfidf_matrix = vectorizer.fit_transform(documents) #  Learns vocabulary and applies TF-IDF.\n",
    "\n",
    "# Step 3: Convert the matrix to a DataFrame for better readability\n",
    "# .toarray() → Converts the sparse matrix to an array.\n",
    "# get_feature_names_out() → Gets the words used in TF-IDF calculation.\n",
    "df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Display the matrix\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions: \n",
    "- Which term has the highest TF-IDF score in each document? \n",
    "- Are there any terms with a score of 0? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1: 'for' has the highest TF-IDF score of 0.3853\n",
      "Document 2: 'are' has the highest TF-IDF score of 0.4120\n",
      "Document 3: 'mathematics' has the highest TF-IDF score of 0.4338\n"
     ]
    }
   ],
   "source": [
    "# Find the term with the highest TF-IDF score in each document\n",
    "highest_terms = df.idxmax(axis=1)  # Finds the term with the max value in each row\n",
    "highest_scores = df.max(axis=1)  # Gets the max score for each document\n",
    "\n",
    "# Display results\n",
    "for i, (term, score) in enumerate(zip(highest_terms, highest_scores)):\n",
    "    print(f\"Document {i+1}: '{term}' has the highest TF-IDF score of {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terms with a score of 0 in at least one document:\n",
      " and            1\n",
      "are            2\n",
      "data           1\n",
      "fields         2\n",
      "for            2\n",
      "great          2\n",
      "is             2\n",
      "language       2\n",
      "learning       1\n",
      "machine        1\n",
      "mathematics    2\n",
      "on             2\n",
      "popular        2\n",
      "programming    1\n",
      "python         2\n",
      "relies         2\n",
      "science        1\n",
      "dtype: int64 Those terms has TF-IDF score 0 in at least in one documents, it's due to it's absent in one documents but present in corpus.\n"
     ]
    }
   ],
   "source": [
    "# Check if any term has a TF-IDF score of 0 in any document\n",
    "zero_terms = (df == 0).sum(axis=0)\n",
    "\n",
    "# Display terms with at least one zero occurrence\n",
    "print(\"Terms with a score of 0 in at least one document:\\n\", zero_terms, \"Those terms has TF-IDF score 0 in at least in one documents, it's due to it's absent in one documents but present in corpus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       data    fields    great  language  learning   machine  mathematics  \\\n",
      "0  0.393511  0.000000  0.51742   0.51742  0.000000  0.000000     0.000000   \n",
      "1  0.366180  0.481482  0.00000   0.00000  0.366180  0.366180     0.000000   \n",
      "2  0.000000  0.000000  0.00000   0.00000  0.459854  0.459854     0.604652   \n",
      "\n",
      "    popular  programming   science  \n",
      "0  0.000000     0.393511  0.393511  \n",
      "1  0.481482     0.000000  0.366180  \n",
      "2  0.000000     0.459854  0.000000  \n"
     ]
    }
   ],
   "source": [
    "# Exercise 2: Customize the TF-IDF Vectorizer \n",
    "\n",
    "# 1. Modify the `TfidfVectorizer` to remove common English stop words. \n",
    "# 2. Use the parameter `max_features=10` to limit the matrix to the top 10 terms.\n",
    "\n",
    "# Initialize TF-IDF Vectorizer with stop words removal and feature limit\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=10)\n",
    "\n",
    "# Fit and transform\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Display updated TF-IDF matrix\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 Most Important Terms in the Corpus:\n",
      "programming    0.853365\n",
      "machine        0.826033\n",
      "learning       0.826033\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#  Identify the top 3 terms across the corpus with the highest importance.\n",
    "\n",
    "# Sum TF-IDF scores for each term across all documents\n",
    "term_importance = df.sum().sort_values(ascending=False)\n",
    "\n",
    "# Get the top 3 most important terms\n",
    "top_3_terms = term_importance.head(3)\n",
    "\n",
    "# Display the top 3 terms\n",
    "print(f\"Top 3 Most Important Terms in the Corpus:\\n{top_3_terms}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Term  Importance\n",
      "8  programming    0.853365\n",
      "5      machine    0.826033\n",
      "4     learning    0.826033\n",
      "0         data    0.759691\n",
      "9      science    0.759691\n",
      "6  mathematics    0.604652\n",
      "2        great    0.517420\n",
      "3     language    0.517420\n",
      "1       fields    0.481482\n",
      "7      popular    0.481482\n"
     ]
    }
   ],
   "source": [
    "# # Exercise 3: Term Importance Analysis \n",
    "\n",
    "# Sum TF-IDF scores across all documents \n",
    "term_importance = tfidf_matrix.sum(axis=0).A1  # Convert sparse matrix to array, A1=Flattens the 2D array into 1D, axis=0: Operate along columns (sum downwards across rows).\n",
    "terms = vectorizer.get_feature_names_out()  # Ensure correct variable name\n",
    "\n",
    "# Create a DataFrame of terms and their importance \n",
    "importance_df = pd.DataFrame({\"Term\": terms, \"Importance\": term_importance}) \n",
    "\n",
    "# Sort terms by importance in descending order\n",
    "importance_df = importance_df.sort_values(by=\"Importance\", ascending=False) \n",
    "\n",
    "# Display the DataFrame\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The most important terms in the corpus are:\n",
      "          Term  Importance\n",
      "8  programming    0.853365\n",
      "5      machine    0.826033\n",
      "4     learning    0.826033\n",
      "0         data    0.759691\n",
      "9      science    0.759691\n",
      "These terms are appears on multiple documents but are not too common across all documents making them strong indicators of the topic.\n"
     ]
    }
   ],
   "source": [
    "# Questions: - Which terms are the most important in the corpus? \n",
    "#            - How do these terms relate to the overall content?\n",
    "print(f\" The most important terms in the corpus are:\\n{importance_df.head(5)}\")\n",
    "print(\"These terms are appears on multiple documents but are not too common across all documents making them strong indicators of the topic.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most important terms:\n",
      "\n",
      "           Term  Importance\n",
      "0          data    0.577350\n",
      "1            ai    0.377964\n",
      "2    automation    0.377964\n",
      "3     solutions    0.377964\n",
      "4  transforming    0.377964\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4: Apply TF-IDF to Your Own Dataset\n",
    "new_documents = [\n",
    "    \"Self-driving cars rely on deep learning and sensor fusion for navigation.\",\n",
    "    \"Big data analytics helps businesses make data-driven decisions efficiently.\",\n",
    "    \"Robotics and automation are transforming industries with AI-powered solutions.\"\n",
    "]\n",
    "# Apply TF-IDF\n",
    "new_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "new_tfidf_matrix = new_vectorizer.fit_transform(new_documents)\n",
    "\n",
    "# Sum TF-IDF scores across all documents \n",
    "new_term_importance = new_tfidf_matrix.sum(axis=0).A1\n",
    "new_terms = new_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Create a DataFrame of terms and their importance, Sort terms by importance in descending order\n",
    "new_importance_df = pd.DataFrame({\"Term\": new_terms, \"Importance\": new_term_importance}).sort_values(by=\"Importance\", ascending=False).reset_index(drop= True) \n",
    "\n",
    "# Display the DataFrame\n",
    "print(f\"Most important terms:\\n\\n{new_importance_df.head(5)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
